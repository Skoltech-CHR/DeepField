{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and samples\n",
    "\n",
    "This notebook demonstrates the functionality of a class called `FieldDataset`.\n",
    "It can be used to solve two possible tasks:\n",
    "- Simplify complexly defined `Field` to a set of `numpy` arrays or `torch` tensors\n",
    "- Iteratively convert instances of the `Field` to their simplified version for iterative model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from deepfield.datasets import FieldDataset, FieldSample\n",
    "from deepfield.datasets.transforms import ToTensor, Normalize, Denormalize, AddBatchDimension\n",
    "\n",
    "from deepfield import Field\n",
    "from deepfield.field.base_component import BaseComponent\n",
    "\n",
    "PATH_TO_DATASET = '../open_data/norne_simplified/'\n",
    "PATH_TO_FIELD = '../open_data/norne_simplified/norne_simplified.data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `FieldDataset` can be created in several ways:\n",
    "1. From a path to a folder with either `.data` or `.hdf5` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = FieldDataset(src=PATH_TO_DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. From a preloaded `Field` instance. In this case, some preprocessing is required for the proper treatment of the control variables. Namely, we should ensure, the well trajectories are computed, and the events are transformed from the ECLIPSE format.\n",
    "\n",
    "**NOTE:** in order to load the solutions of the *standard commercial simulator* available for the `norne_simplified`, unzip the file with results `../open_data/norne_simplified/RESULTS.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:Field:Using default config.\n",
      "WARNING:Field:norne_simplified.UNRST file was not found.\n",
      "INFO:Field:Start reading X files.\n",
      "...\n",
      "INFO:Field:===== Field summary =====\n",
      "INFO:Field:GRID attributes: MAPAXES, ZCORN, COORD, ACTNUM, DIMENS\n",
      "INFO:Field:ROCK attributes: PORO, PERMX, PERMY, PERMZ\n",
      "INFO:Field:STATES attributes: PRESSURE, RS, SGAS, SOIL, SWAT\n",
      "INFO:Field:TABLES attributes: PVTO, ROCK, PVTW, DENSITY, SWOF, SGOF, PVDG\n",
      "INFO:Field:WELLS attributes: WELLTRACK, RESULTS, WCONINJE, COMPDAT, WELSPECS, WCONPROD\n",
      "INFO:Field:AQUIFERS attributes: \n",
      "INFO:Field:=========================\n",
      "INFO:Field:Grid pillars (`COORD`) are mapped to new axis with respect to `MAPAXES`.\n"
     ]
    }
   ],
   "source": [
    "field = Field(PATH_TO_FIELD).load()\n",
    "dataset = FieldDataset(src=field, allow_change_preloaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Roughly speaking, `FieldDataset` is a generator: at each iteration it loads the `Field` and simplifies it.\n",
    "The simplified `Field` has its own class - `FieldSample`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'deepfield.datasets.datasets.FieldSample'>\n"
     ]
    }
   ],
   "source": [
    "for sample in dataset:\n",
    "    print(sample.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`FieldSample` is a child class of the `BaseComponent`. It has the same interface and has attributes which are either arrays/tensors or `BaseComponents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MASKS', 'GRID', 'ROCK', 'STATES', 'CONTROL')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATES is a numpy array: True\n"
     ]
    }
   ],
   "source": [
    "print('STATES is a numpy array: %s' % isinstance(sample.states, np.ndarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASKS is a BaseComponent: True\n",
      "MASKS.ACTNUM is a numpy array: True\n"
     ]
    }
   ],
   "source": [
    "print('MASKS is a BaseComponent: %s' % isinstance(sample.masks, BaseComponent))\n",
    "print('MASKS.ACTNUM is a numpy array: %s' % isinstance(sample.masks.actnum, np.ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The characteristics that are 'stackable' together are stacked: STATES, ROCK, CONTROL, etc..\n",
    "\n",
    "The characteristics that have more complex shapes are represented as `BaseComponents`: MASKS, GRID, etc..\n",
    "\n",
    "All the characteristic's names presented in the `FieldSample` are stored in the `sample_attrs` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE_ATTRS is a BaseComponent: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MASKS': ['ACTNUM', 'TIME'],\n",
       " 'GRID': [],\n",
       " 'ROCK': ['PORO', 'PERMX', 'PERMY', 'PERMZ'],\n",
       " 'STATES': ['PRESSURE', 'RS', 'SGAS', 'SOIL', 'SWAT'],\n",
       " 'CONTROL': ['BHPT']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('SAMPLE_ATTRS is a BaseComponent: %s' % isinstance(sample.sample_attrs, BaseComponent))\n",
    "dict(**sample.sample_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can specify `sample_attrs` by passing an appropriate `dict` to the `FieldDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MASKS': ['ACTNUM',\n",
       "  'TIME',\n",
       "  'NAMED_WELL_MASK',\n",
       "  'WELL_MASK',\n",
       "  'CF_MASK',\n",
       "  'PERF_MASK'],\n",
       " 'STATES': ['PRESSURE', 'SOIL', 'SWAT', 'SGAS', 'RS'],\n",
       " 'ROCK': ['PORO', 'PERMX', 'PERMY', 'PERMZ'],\n",
       " 'CONTROL': ['BHPT'],\n",
       " 'TABLES': ['PVTO', 'PVTW', 'PVDG', 'SWOF', 'SGOF', 'DENSITY'],\n",
       " 'GRID': ['XYZ']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_attrs = {\n",
    "    'masks': ['actnum', 'time', 'named_well_mask', 'well_mask', 'cf_mask', 'perf_mask'],\n",
    "    'states': ['pressure', 'soil', 'swat', 'sgas', 'rs'],\n",
    "    'rock': ['poro', 'permx', 'permy', 'permz'],\n",
    "    'control': ['bhpt'],\n",
    "    'tables': ['pvto', 'pvtw', 'pvdg', 'swof', 'sgof', 'density'],\n",
    "    'grid': ['xyz']\n",
    "}\n",
    "dataset = FieldDataset(src=field, sample_attrs=sample_attrs)\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "dict(**sample.sample_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Unlike the `BaseComponent`, `FieldSample` has several methods for specific transformations:\n",
    "\n",
    "- You can apply any transform from `deepfield.dataset.transforms` to it\n",
    "- You can change the spatial representation of the sample: `ravel` and `crop_at_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATES shape before \"as_ravel\": [246, 5, 46, 112, 22]\n",
      "STATES shape after \"as_ravel\": [246, 5, 44431]\n"
     ]
    }
   ],
   "source": [
    "print('STATES shape before \"as_ravel\": %s' % list(sample.states.shape))\n",
    "sample_ravel = sample.as_ravel(inplace=False, crop_at_mask='ACTNUM')\n",
    "print('STATES shape after \"as_ravel\": %s' % list(sample_ravel.states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`sample.at_wells()` is a shortcut for `sample.ravel(crop_at_mask='WELL_MASK')`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATES shape after \"at_wells\": [246, 5, 504]\n"
     ]
    }
   ],
   "source": [
    "sample_at_wells = sample.at_wells(inplace=False) \n",
    "print('STATES shape after \"at_wells\": %s' % list(sample_at_wells.states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The transforms from `deepfield.dataset.transforms` can be used for e.g. convertion to `torch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATES is a torch tensor: True\n"
     ]
    }
   ],
   "source": [
    "sample.transformed(ToTensor, inplace=True)\n",
    "print('STATES is a torch tensor: %s' % isinstance(sample.states, torch.Tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some of the useful information about sample's representation can be found in its `state`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_attributes': <deepfield.field.base_component.BaseComponent at 0x7f0d09b61990>,\n",
       " 'spatial': True,\n",
       " 'cropped_at_mask': None,\n",
       " 'numpy': False,\n",
       " 'tensor': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.state.as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can ask the `FieldDataset` to apply transforms to all the generated samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATES shape with batch dimension: [1, 246, 5, 46, 112, 22]\n"
     ]
    }
   ],
   "source": [
    "dataset = FieldDataset(src=field, sample_attrs=sample_attrs)\n",
    "dataset.set_transform([ToTensor, AddBatchDimension])\n",
    "\n",
    "sample = next(iter(dataset))\n",
    "print('STATES shape with batch dimension: %s' % list(sample.states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For training, it is useful to normalize values before passing them into an ML model.\n",
    "\n",
    "There is a pair of `Normalize` and `Denormalize` transforms for that. \n",
    "However, they will not work before the statistics (mean, std, min, max) across the dataset are calculated.\n",
    "Statistics calculation is a prerogative of the `FieldDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = FieldDataset(src=field, sample_attrs=sample_attrs, allow_change_preloaded=True)\n",
    "dataset.calculate_statistics()\n",
    "sample = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can dump and load precalculated statistics (pickle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset.dump_statistics('statistics.pkl')\n",
    "dataset.load_statistics('statistics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATES max value before normalization: 312.58\n",
      "STATES max value after normalization: 4.56\n",
      "STATES max value after denormalization: 312.58\n"
     ]
    }
   ],
   "source": [
    "print('STATES max value before normalization: %.2f' % sample.states.max())\n",
    "sample.transformed([ToTensor, Normalize], inplace=True)\n",
    "print('STATES max value after normalization: %.2f' % sample.states.max())\n",
    "sample.transformed([Denormalize], inplace=True)\n",
    "print('STATES max value after denormalization: %.2f' % sample.states.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also dump and load the sample itself (`state=True` dumps the `sample.state` too):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample.dump('sample.hdf5', state=True)\n",
    "sample = FieldSample('sample.hdf5').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CONTROL', 'GRID', 'MASKS', 'ROCK', 'STATES', 'TABLES')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}